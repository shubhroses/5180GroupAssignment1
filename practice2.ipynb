{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "indToDoc = {}\n",
    "postingList = collections.defaultdict(list)\n",
    "curDocID = 0\n",
    "path = \"practice2_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(f, path):\n",
    "    #Returns [(term, pos), (term, pos) ...]\n",
    "    terms = []\n",
    "    with open(path + \"/\" + f) as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            # Regex to match only strings and spaces \n",
    "            line = re.sub(r'[^A-Za-z\\s]+', '', line)\n",
    "            for i, word in enumerate(line.split()):\n",
    "                terms.append((word.lower(), file.tell()+i))\n",
    "            line = file.readline() \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPostingList(path):\n",
    "    startTime = time.time()\n",
    "    for f in os.listdir(path):\n",
    "        # TODO: remove in real code\n",
    "        global curDocID\n",
    "        \n",
    "        indToDoc[curDocID] = f\n",
    "\n",
    "        # Returns [(word, pos), (word, pos) ...]\n",
    "        terms = tokenize(f, path)\n",
    "\n",
    "        # create map {word:[pos1, pos2, pos3]}\n",
    "        wordToPos = collections.defaultdict(list)\n",
    "        for word, pos in terms:\n",
    "            wordToPos[word].append(pos)\n",
    "\n",
    "        # append to posting list {term : [(docID1, [pos1, pos2, pos3, pos4])]}\n",
    "        for term, arr in wordToPos.items():\n",
    "            postingList[term].append((curDocID, wordToPos[term]))\n",
    "\n",
    "        # For every file update id \n",
    "        curDocID += 1\n",
    "    \n",
    "    endTime = time.time()\n",
    "    print(f\"Index built in {endTime - startTime} seconds.\")\n",
    "    return postingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built in 0.0011179447174072266 seconds.\n"
     ]
    }
   ],
   "source": [
    "result = createPostingList(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPostingList = collections.defaultdict(list)\n",
    "idToTerm = {}\n",
    "curTermIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are', 'with', 'that', 'will', 'be', 'it', 'of', 'has', 'was', 'at', 'and', 'on', 'for', 'were', 'he', 'an', 'as', 'by', 'its', 'in', 'to', 'a', 'is', 'the', 'from'}\n"
     ]
    }
   ],
   "source": [
    "stopList = set()\n",
    "stopTuples = tokenize(\"stop-list.txt\", \".\")\n",
    "for t, p in stopTuples:\n",
    "    stopList.add(t)\n",
    "print(stopList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    # if k in stopList:\n",
    "    #     continue\n",
    "    idToTerm[curTermIndex] = k\n",
    "    newPostingList[curTermIndex].append(math.log10(len(indToDoc)/len(v)))\n",
    "    \n",
    "    for docId, posList in v:\n",
    "        newPostingList[curTermIndex].append((docId, 1 + math.log10(len(posList)), posList))\n",
    "    curTermIndex += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'the', 1: 'best', 2: 'american', 3: 'restaurant', 4: 'italian', 5: 'enjoy', 6: 'pasta', 7: 'hamburger', 8: 'korean', 9: 'bibimbap'}\n"
     ]
    }
   ],
   "source": [
    "print(idToTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "docToVec = {}\n",
    "for k in indToDoc.keys():\n",
    "    docToVec[k] = len(idToTerm)*[float(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "print(docToVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 Term: the Val: 0.0\n",
      "D2 Term: the Val: 0.0\n",
      "D3 Term: the Val: 0.0\n",
      "D4 Term: the Val: 0.0\n",
      "D1 Term: best Val: 0.0\n",
      "D2 Term: best Val: 0.0\n",
      "D3 Term: best Val: 0.0\n",
      "D4 Term: best Val: 0.0\n",
      "D1 Term: american Val: 0.3010299956639812\n",
      "D3 Term: american Val: 0.3010299956639812\n",
      "D1 Term: restaurant Val: 0.0\n",
      "D2 Term: restaurant Val: 0.0\n",
      "D3 Term: restaurant Val: 0.0\n",
      "D4 Term: restaurant Val: 0.0\n",
      "D2 Term: italian Val: 0.6020599913279624\n",
      "D2 Term: enjoy Val: 0.12493873660829993\n",
      "D3 Term: enjoy Val: 0.12493873660829993\n",
      "D4 Term: enjoy Val: 0.12493873660829993\n",
      "D2 Term: pasta Val: 0.6020599913279624\n",
      "D3 Term: hamburger Val: 0.6020599913279624\n",
      "D4 Term: korean Val: 0.6020599913279624\n",
      "D4 Term: bibimbap Val: 0.6020599913279624\n"
     ]
    }
   ],
   "source": [
    "for k, v in newPostingList.items():\n",
    "    idf = v[0]\n",
    "    for i in range(1, len(v)):\n",
    "        t = v[i]\n",
    "        doc, w = t[0], t[1]\n",
    "        docToVec[doc][k] = idf*w\n",
    "        print(f\"D{doc + 1} Term: {idToTerm[k]} Val: {idf*w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d4.txt : [0.0, 0.0, 0.3010299956639812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "d1.txt : [0.0, 0.0, 0.0, 0.0, 0.6020599913279624, 0.12493873660829993, 0.6020599913279624, 0.0, 0.0, 0.0]\n",
      "d2.txt : [0.0, 0.0, 0.3010299956639812, 0.0, 0.0, 0.12493873660829993, 0.0, 0.6020599913279624, 0.0, 0.0]\n",
      "d3.txt : [0.0, 0.0, 0.0, 0.0, 0.0, 0.12493873660829993, 0.0, 0.0, 0.6020599913279624, 0.6020599913279624]\n"
     ]
    }
   ],
   "source": [
    "for k, v in docToVec.items():\n",
    "    print(f\"{indToDoc[k]} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [0.0, (0, 1.3010299956639813, [37, 39]), (1, 1.3010299956639813, [48, 53]), (2, 1.0, [47]), (3, 1.0, [45])]\n",
      "best : [0.0, (0, 1.3010299956639813, [38, 40]), (1, 1.3010299956639813, [49, 54]), (2, 1.0, [48]), (3, 1.0, [46])]\n",
      "american : [0.3010299956639812, (0, 1.0, [41]), (2, 1.0, [44])]\n",
      "restaurant : [0.0, (0, 1.0, [42]), (1, 1.0, [51]), (2, 1.0, [45]), (3, 1.0, [43])]\n",
      "italian : [0.6020599913279624, (1, 1.0, [50])]\n",
      "enjoy : [0.12493873660829993, (1, 1.0, [52]), (2, 1.0, [46]), (3, 1.0, [44])]\n",
      "pasta : [0.6020599913279624, (1, 1.0, [55])]\n",
      "hamburger : [0.6020599913279624, (2, 1.0, [49])]\n",
      "korean : [0.6020599913279624, (3, 1.0, [42])]\n",
      "bibimbap : [0.6020599913279624, (3, 1.0, [47])]\n"
     ]
    }
   ],
   "source": [
    "for k, v in newPostingList.items():\n",
    "    print(f\"{idToTerm[k]} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [(0, [14]), (1, [14])]\n",
      "dog : [(0, [15]), (1, [15])]\n",
      "barked : [(0, [16])]\n",
      "jumped : [(1, [16]), (2, [14])]\n",
      "a : [(2, [12])]\n",
      "cat : [(2, [13])]\n"
     ]
    }
   ],
   "source": [
    "for k,v in result.items():\n",
    "    print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [(0, [14]), (1, [14])] idf: 0.17609125905568124\n",
      "dog : [(0, [15]), (1, [15])] idf: 0.17609125905568124\n",
      "barked : [(0, [16])] idf: 0.47712125471966244\n",
      "jumped : [(1, [16]), (2, [14])] idf: 0.17609125905568124\n",
      "a : [(2, [12])] idf: 0.47712125471966244\n",
      "cat : [(2, [13])] idf: 0.47712125471966244\n"
     ]
    }
   ],
   "source": [
    "for k, v in result.items():\n",
    "    print(f\"{k} : {v} idf: {math.log10(len(indToDoc)/len(v))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, [14] term frequency = 1 w = 1.0\n",
      "1, [14] term frequency = 1 w = 1.0\n",
      "0, [15] term frequency = 1 w = 1.0\n",
      "1, [15] term frequency = 1 w = 1.0\n",
      "0, [16] term frequency = 1 w = 1.0\n",
      "1, [16] term frequency = 1 w = 1.0\n",
      "2, [14] term frequency = 1 w = 1.0\n",
      "2, [12] term frequency = 1 w = 1.0\n",
      "2, [13] term frequency = 1 w = 1.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in result.items():\n",
    "    for docId, posList in v:\n",
    "        print(f\"{docId}, {posList} term frequency = {len(posList)} w = {1 + math.log10(len(posList))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "N = 1000000\n",
    "dft = 100\n",
    "print(math.log10(N/dft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(math\u001b[38;5;241m.\u001b[39mlog10(\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(math.log10(10/0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
