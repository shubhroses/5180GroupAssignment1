{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "indToDoc = {}\n",
    "postingList = collections.defaultdict(list)\n",
    "curDocID = 0\n",
    "path = \"practice_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(f, path):\n",
    "    #Returns [(term, pos), (term, pos) ...]\n",
    "    terms = []\n",
    "    with open(path + \"/\" + f) as file:\n",
    "        line = file.readline()\n",
    "        i = 0\n",
    "        while line:\n",
    "            # Regex to match only strings and spaces \n",
    "            line = re.sub(r'[^A-Za-z\\s]+', '', line)\n",
    "            for word in line.split():\n",
    "                terms.append((word.lower(), i))\n",
    "                i += 1\n",
    "            line = file.readline() \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPostingList(path):\n",
    "    startTime = time.time()\n",
    "    for f in os.listdir(path):\n",
    "        # TODO: remove in real code\n",
    "        global curDocID\n",
    "        \n",
    "        indToDoc[curDocID] = f\n",
    "\n",
    "        # Returns [(word, pos), (word, pos) ...]\n",
    "        terms = tokenize(f, path)\n",
    "\n",
    "        # create map {word:[pos1, pos2, pos3]}\n",
    "        wordToPos = collections.defaultdict(list)\n",
    "        for word, pos in terms:\n",
    "            wordToPos[word].append(pos)\n",
    "\n",
    "        # append to posting list {term : [(docID1, [pos1, pos2, pos3, pos4])]}\n",
    "        for term, arr in wordToPos.items():\n",
    "            postingList[term].append((curDocID, wordToPos[term]))\n",
    "\n",
    "        # For every file update id \n",
    "        curDocID += 1\n",
    "    \n",
    "    endTime = time.time()\n",
    "    print(f\"Index built in {endTime - startTime} seconds.\")\n",
    "    return postingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built in 0.0020380020141601562 seconds.\n"
     ]
    }
   ],
   "source": [
    "result = createPostingList(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPostingList = collections.defaultdict(list)\n",
    "idToTerm = {}\n",
    "curTermIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are', 'with', 'that', 'will', 'be', 'it', 'of', 'has', 'was', 'at', 'and', 'on', 'for', 'were', 'he', 'an', 'as', 'by', 'its', 'in', 'to', 'a', 'is', 'the', 'from'}\n"
     ]
    }
   ],
   "source": [
    "stopList = set()\n",
    "stopTuples = tokenize(\"stop-list.txt\", \".\")\n",
    "for t, p in stopTuples:\n",
    "    stopList.add(t)\n",
    "print(stopList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    # if k in stopList:\n",
    "    #     continue\n",
    "    idToTerm[curTermIndex] = k\n",
    "    newPostingList[curTermIndex].append(math.log10(len(indToDoc)/len(v)))\n",
    "    \n",
    "    for docId, posList in v:\n",
    "        newPostingList[curTermIndex].append((docId, 1 + math.log10(len(posList)), posList))\n",
    "    curTermIndex += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'the', 1: 'dog', 2: 'barked', 3: 'jumped', 4: 'a', 5: 'cat'}\n"
     ]
    }
   ],
   "source": [
    "print(idToTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "termToId = {}\n",
    "for id, term in idToTerm.items():\n",
    "    termToId[term] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "docToVec = {}\n",
    "for k in indToDoc.keys():\n",
    "    docToVec[k] = len(idToTerm)*[float(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "print(docToVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in newPostingList.items():\n",
    "    idf = v[0]\n",
    "    for i in range(1, len(v)):\n",
    "        t = v[i]\n",
    "        doc, w = t[0], t[1]\n",
    "        docToVec[doc][k] = idf*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1.txt : [0.17609125905568124, 0.17609125905568124, 0.47712125471966244, 0.0, 0.0, 0.0]\n",
      "d2.txt : [0.17609125905568124, 0.17609125905568124, 0.0, 0.17609125905568124, 0.0, 0.0]\n",
      "d3.txt : [0.0, 0.0, 0.0, 0.17609125905568124, 0.47712125471966244, 0.47712125471966244]\n"
     ]
    }
   ],
   "source": [
    "for k, v in docToVec.items():\n",
    "    print(f\"{indToDoc[k]} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37780020399389935\n"
     ]
    }
   ],
   "source": [
    "d1Vec = docToVec[0]\n",
    "d2Vec = docToVec[1]\n",
    "\n",
    "print(cosine_similarity(d1Vec, d2Vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 0), ('dog', 1), ('barked', 2), ('jumped', 3)]\n"
     ]
    }
   ],
   "source": [
    "query = \"the dog barked jumped\"\n",
    "terms = []\n",
    "line = re.sub(r'[^A-Za-z\\s]+', '', query)\n",
    "for i, word in enumerate(line.split()):\n",
    "    terms.append((word.lower(), i))\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'dog': 1, 'barked': 1, 'jumped': 1}\n"
     ]
    }
   ],
   "source": [
    "termToFreq = {}\n",
    "for t, p in terms:\n",
    "    termToFreq[t] = termToFreq.get(t, 0) + 1\n",
    "print(termToFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryVector = len(idToTerm)*[float(0)]\n",
    "for term, freq in termToFreq.items():\n",
    "    if term in termToId:\n",
    "        w = 1 + math.log10(freq)\n",
    "        idf = newPostingList[termToId[term]][0]\n",
    "        queryVector[termToId[term]] = w*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17609125905568124, 0.17609125905568124, 0.47712125471966244, 0.17609125905568124, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(queryVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "docToSimilarity = []\n",
    "for doc, vec in docToVec.items():\n",
    "    docToSimilarity.append((doc, cosine_similarity(queryVector, vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.950421893058099), (1, 0.5386043776164267), (2, 0.07852284477467995)]\n"
     ]
    }
   ],
   "source": [
    "print(docToSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [0.0, (0, 1.3010299956639813, [37, 39]), (1, 1.3010299956639813, [48, 53]), (2, 1.0, [47]), (3, 1.0, [45])]\n",
      "best : [0.0, (0, 1.3010299956639813, [38, 40]), (1, 1.3010299956639813, [49, 54]), (2, 1.0, [48]), (3, 1.0, [46])]\n",
      "american : [0.3010299956639812, (0, 1.0, [41]), (2, 1.0, [44])]\n",
      "restaurant : [0.0, (0, 1.0, [42]), (1, 1.0, [51]), (2, 1.0, [45]), (3, 1.0, [43])]\n",
      "italian : [0.6020599913279624, (1, 1.0, [50])]\n",
      "enjoy : [0.12493873660829993, (1, 1.0, [52]), (2, 1.0, [46]), (3, 1.0, [44])]\n",
      "pasta : [0.6020599913279624, (1, 1.0, [55])]\n",
      "hamburger : [0.6020599913279624, (2, 1.0, [49])]\n",
      "korean : [0.6020599913279624, (3, 1.0, [42])]\n",
      "bibimbap : [0.6020599913279624, (3, 1.0, [47])]\n"
     ]
    }
   ],
   "source": [
    "for k, v in newPostingList.items():\n",
    "    print(f\"{idToTerm[k]} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [(0, [14]), (1, [14])]\n",
      "dog : [(0, [15]), (1, [15])]\n",
      "barked : [(0, [16])]\n",
      "jumped : [(1, [16]), (2, [14])]\n",
      "a : [(2, [12])]\n",
      "cat : [(2, [13])]\n"
     ]
    }
   ],
   "source": [
    "for k,v in result.items():\n",
    "    print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : [(0, [14]), (1, [14])] idf: 0.17609125905568124\n",
      "dog : [(0, [15]), (1, [15])] idf: 0.17609125905568124\n",
      "barked : [(0, [16])] idf: 0.47712125471966244\n",
      "jumped : [(1, [16]), (2, [14])] idf: 0.17609125905568124\n",
      "a : [(2, [12])] idf: 0.47712125471966244\n",
      "cat : [(2, [13])] idf: 0.47712125471966244\n"
     ]
    }
   ],
   "source": [
    "for k, v in result.items():\n",
    "    print(f\"{k} : {v} idf: {math.log10(len(indToDoc)/len(v))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, [14] term frequency = 1 w = 1.0\n",
      "1, [14] term frequency = 1 w = 1.0\n",
      "0, [15] term frequency = 1 w = 1.0\n",
      "1, [15] term frequency = 1 w = 1.0\n",
      "0, [16] term frequency = 1 w = 1.0\n",
      "1, [16] term frequency = 1 w = 1.0\n",
      "2, [14] term frequency = 1 w = 1.0\n",
      "2, [12] term frequency = 1 w = 1.0\n",
      "2, [13] term frequency = 1 w = 1.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in result.items():\n",
    "    for docId, posList in v:\n",
    "        print(f\"{docId}, {posList} term frequency = {len(posList)} w = {1 + math.log10(len(posList))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "N = 1000000\n",
    "dft = 100\n",
    "print(math.log10(N/dft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(math\u001b[38;5;241m.\u001b[39mlog10(\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(math.log10(10/0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
