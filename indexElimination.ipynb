{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Old Postring List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indToDoc = {}\n",
    "postingList = collections.defaultdict(list)\n",
    "curDocID = 0\n",
    "path = \"practice_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(f, path):\n",
    "    #Returns [(term, pos), (term, pos) ...]\n",
    "    terms = []\n",
    "    with open(path + \"/\" + f) as file:\n",
    "        line = file.readline()\n",
    "        i = 0\n",
    "        while line:\n",
    "            # Regex to match only strings and spaces \n",
    "            line = re.sub(r'[^A-Za-z\\s]+', '', line)\n",
    "            for word in line.split():\n",
    "                terms.append((word.lower(), i))\n",
    "                i += 1\n",
    "            line = file.readline() \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPostingList(path):\n",
    "    startTime = time.time()\n",
    "    for f in os.listdir(path):\n",
    "        # TODO: remove in real code\n",
    "        global curDocID\n",
    "        \n",
    "        indToDoc[curDocID] = f\n",
    "\n",
    "        # Returns [(word, pos), (word, pos) ...]\n",
    "        terms = tokenize(f, path)\n",
    "\n",
    "        # create map {word:[pos1, pos2, pos3]}\n",
    "        wordToPos = collections.defaultdict(list)\n",
    "        for word, pos in terms:\n",
    "            wordToPos[word].append(pos)\n",
    "\n",
    "        # append to posting list {term : [(docID1, [pos1, pos2, pos3, pos4])]}\n",
    "        for term, arr in wordToPos.items():\n",
    "            postingList[term].append((curDocID, wordToPos[term]))\n",
    "\n",
    "        # For every file update id \n",
    "        curDocID += 1\n",
    "    \n",
    "    endTime = time.time()\n",
    "    print(f\"Index built in {endTime - startTime} seconds.\")\n",
    "    return postingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built in 0.0009500980377197266 seconds.\n"
     ]
    }
   ],
   "source": [
    "result = createPostingList(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create New Postring List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPostingList = collections.defaultdict(list)\n",
    "idToTerm = {}\n",
    "curTermIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'as', 'the', 'to', 'by', 'of', 'in', 'on', 'it', 'a', 'its', 'at', 'will', 'that', 'is', 'and', 'were', 'are', 'an', 'for', 'from', 'be', 'has', 'was', 'he', 'with'}\n"
     ]
    }
   ],
   "source": [
    "stopList = set()\n",
    "stopTuples = tokenize(\"stop-list.txt\", \".\")\n",
    "for t, p in stopTuples:\n",
    "    stopList.add(t)\n",
    "print(stopList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    # if k in stopList:\n",
    "    #     continue\n",
    "    idToTerm[curTermIndex] = k\n",
    "    newPostingList[curTermIndex].append(math.log10(len(indToDoc)/len(v)))\n",
    "    \n",
    "    for docId, posList in v:\n",
    "        newPostingList[curTermIndex].append((docId, 1 + math.log10(len(posList)), posList))\n",
    "    curTermIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: [0.17609125905568124, (0, 1.0, [0]), (1, 1.0, [0])], 1: [0.17609125905568124, (0, 1.0, [1]), (1, 1.0, [1])], 2: [0.47712125471966244, (0, 1.0, [2])], 3: [0.17609125905568124, (1, 1.0, [2]), (2, 1.0, [2])], 4: [0.47712125471966244, (2, 1.0, [0])], 5: [0.47712125471966244, (2, 1.0, [1])]})\n"
     ]
    }
   ],
   "source": [
    "print(newPostingList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Each Document To A Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docToVec = {}\n",
    "for k in indToDoc.keys():\n",
    "    docToVec[k] = len(idToTerm)*[float(0)]\n",
    "\n",
    "for k, v in newPostingList.items():\n",
    "    idf = v[0]\n",
    "    for i in range(1, len(v)):\n",
    "        t = v[i]\n",
    "        doc, w = t[0], t[1]\n",
    "        docToVec[doc][k] = idf*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    if sumxx == 0 or sumyy == 0:\n",
    "        return 0\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep terms with heigher idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_terms = [\"a\", \"cat\", \"jumped\"]\n",
    "query_terms = [word.lower() for word in query_terms]\n",
    "\n",
    "termToId = {}\n",
    "for id, term in idToTerm.items():\n",
    "    termToId[term] = id\n",
    "\n",
    "termToIDF = []\n",
    "for term in query_terms:\n",
    "    if term in termToId:\n",
    "        termToIDF.append((term, newPostingList[termToId[term]][0]))\n",
    "\n",
    "termToIDF.sort(key=lambda x:x[1], reverse=True)\n",
    "query_terms = [tuple[0] for tuple in termToIDF[:len(termToIDF)//2]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Query Vector by getting frequency of each term, multiplying it by idf of term, and putting it at index of term in query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "termToFreq = {}\n",
    "for t in query_terms:\n",
    "    termToFreq[t] = termToFreq.get(t, 0) + 1\n",
    "\n",
    "queryVector = len(idToTerm)*[float(0)]\n",
    "for term, freq in termToFreq.items():\n",
    "    if term in termToId:\n",
    "        w = 1 + math.log10(freq)\n",
    "        idf = newPostingList[termToId[term]][0]\n",
    "        queryVector[termToId[term]] = w*idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cosine similaity of each doc vector to the query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docToSimilarity = []\n",
    "for doc, vec in docToVec.items(): \n",
    "    docToSimilarity.append((doc, cosine_similarity(queryVector, vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d3.txt', 'd1.txt']\n"
     ]
    }
   ],
   "source": [
    "docToSimilarity.sort(key = lambda x:x[1], reverse=True)\n",
    "print([indToDoc[t[0]] for t in docToSimilarity[:2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
